"""
Agents cho Agentic RAG System
ƒê·ªãnh nghƒ©a c√°c agents th·ª±c hi·ªán c√°c nhi·ªám v·ª• c·ª• th·ªÉ
"""

from typing import List, Dict, Any, Optional, TypedDict
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from .tools import (
    VectorSearchTool, 
    QueryReformulationTool, 
    QueryAnalysisTool,
    InformationExtractionTool,
    ValidationTool
)
from .config import model_config, agent_config, system_config


class AgentState(TypedDict):
    """State ƒë∆∞·ª£c share gi·ªØa c√°c agents trong workflow"""
    # Input
    original_query: str
    conversation_history: List[Dict[str, str]]
    
    # Query Analysis
    query_analysis: Optional[Dict[str, Any]]
    reformulated_queries: List[str]
    
    # Retrieval
    retrieved_documents: List[Dict[str, Any]]
    retrieval_strategy: str
    
    # Reasoning
    reasoning_steps: List[str]
    intermediate_answers: List[str]
    
    # Response
    final_answer: str
    confidence_score: float
    citations: List[str]
    
    # Validation
    validation_result: Optional[Dict[str, Any]]
    needs_retry: bool
    retry_count: int
    
    # Metadata
    current_step: str
    error_message: Optional[str]


class QueryAnalyzerAgent:
    """
    Agent ph√¢n t√≠ch query c·ªßa user
    Nhi·ªám v·ª•: Hi·ªÉu intent, tr√≠ch xu·∫•t entities, x√°c ƒë·ªãnh complexity
    """
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.analysis_tool = QueryAnalysisTool(llm)
        
        # Import normalizer
        try:
            from .query_normalizer import normalizer
            self.normalizer = normalizer
        except ImportError:
            print("‚ö†Ô∏è Query normalizer not found, slang/abbreviation support disabled")
            self.normalizer = None
    
    def analyze(self, state: AgentState) -> AgentState:
        """Ph√¢n t√≠ch query v√† c·∫≠p nh·∫≠t state"""
        query = state["original_query"].strip()
        conversation_history = state.get("conversation_history", [])
        
        # NORMALIZE QUERY - Chu·∫©n h√≥a t·ª´ l√≥ng v√† vi·∫øt t·∫Øt
        original_query = query
        if self.normalizer:
            query = self.normalizer.normalize(query)
            
            # Log n·∫øu c√≥ thay ƒë·ªïi
            if query != original_query and system_config.verbose:
                print(f"\nüìù [QueryNormalizer] Original: {original_query}")
                print(f"‚úÖ [QueryNormalizer] Normalized: {query}")
                explanations = self.normalizer.get_explanation(original_query)
                if explanations:
                    print(f"   Terms normalized: {dict(explanations)}")
        
        if system_config.verbose:
            print(f"\nüîç [QueryAnalyzer] Analyzing query: {query}")
        
        # QUERY CLASSIFICATION - Ph√¢n lo·∫°i query tr∆∞·ªõc khi retrieval
        query_type = self._classify_query(query, conversation_history)
        
        if system_config.verbose:
            print(f"   Query type: {query_type}")
        
        # X·ª≠ l√Ω theo lo·∫°i query
        if query_type == "greeting":
            # Ch√†o h·ªèi - kh√¥ng c·∫ßn retrieval
            state["query_analysis"] = {
                "intent": "greeting",
                "complexity": "simple",
                "needs_retrieval": False,
                "direct_response": self._handle_greeting(query)
            }
        elif query_type == "meta_conversation":
            # C√¢u h·ªèi v·ªÅ ch√≠nh cu·ªôc h·ªôi tho·∫°i
            state["query_analysis"] = {
                "intent": "meta_conversation",
                "complexity": "simple",
                "needs_retrieval": False,
                "direct_response": self._handle_meta_question(query, conversation_history)
            }
        elif query_type == "chitchat":
            # Chitchat kh√¥ng li√™n quan t√†i li·ªáu
            state["query_analysis"] = {
                "intent": "chitchat",
                "complexity": "simple",
                "needs_retrieval": False,
                "direct_response": self._handle_chitchat(query)
            }
        elif query_type == "out_of_domain":
            # C√¢u h·ªèi ngo√†i domain - t·ª´ ch·ªëi l·ªãch s·ª±
            state["query_analysis"] = {
                "intent": "out_of_domain",
                "complexity": "simple",
                "needs_retrieval": False,
                "direct_response": self._handle_out_of_domain(query)
            }
        else:
            # Document-related query - ti·∫øn h√†nh ph√¢n t√≠ch b√¨nh th∆∞·ªùng
            analysis = self.analysis_tool.analyze(query)
            analysis["needs_retrieval"] = True
            state["query_analysis"] = analysis
            
            if system_config.verbose:
                print(f"   Intent: {analysis.get('intent', 'unknown')}")
                print(f"   Complexity: {analysis.get('complexity', 'unknown')}")
                print(f"   Key terms: {analysis.get('key_terms', [])}")
        
        state["current_step"] = "query_analyzed"
        return state
    
    def _classify_query(self, query:str, history: List[Dict[str, str]]) -> str:
        """Ph√¢n lo·∫°i query: greeting, meta_conversation, chitchat, out_of_domain, document_related"""
        query_lower = query.lower()
        
        # Greetings
        greeting_patterns = [
            "xin ch√†o", "ch√†o", "hello", "hi", "hey",
            "ch√†o b·∫°n", "ch√†o bot", "bu·ªïi s√°ng", "bu·ªïi chi·ªÅu", "bu·ªïi t·ªëi"
        ]
        if any(pattern in query_lower for pattern in greeting_patterns) and len(query.split()) <= 5:
            return "greeting"
        
        # Meta-conversation questions (v·ªÅ ch√≠nh cu·ªôc h·ªôi tho·∫°i)
        meta_patterns = [
            "t√¥i v·ª´a h·ªèi", "c√¢u h·ªèi tr∆∞·ªõc", "b·∫°n v·ª´a n√≥i",
            "t√¥i h·ªèi g√¨", "t√¥i ƒë√£ h·ªèi", "c√¢u tr∆∞·ªõc",
            "what did i ask", "previous question"
        ]
        if any(pattern in query_lower for pattern in meta_patterns):
            return "meta_conversation"
        
        # Chitchat kh√¥ng li√™n quan t√†i li·ªáu
        chitchat_patterns = [
            "b·∫°n l√† ai", "t√™n b·∫°n l√† g√¨", "b·∫°n l√†m ƒë∆∞·ª£c g√¨",
            "who are you", "what's your name", "how are you",
            "c·∫£m ∆°n", "thank you", "thanks", "ok", "t·∫°m bi·ªát", "bye"
        ]
        if any(pattern in query_lower for pattern in chitchat_patterns):
            return "chitchat"
        
        # OUT OF DOMAIN - C√¢u h·ªèi ho√†n to√†n kh√¥ng li√™n quan quy ch·∫ø ƒë√†o t·∫°o
        out_of_domain_patterns = [
            # To√°n h·ªçc
            "ph∆∞∆°ng tr√¨nh", "ƒë·∫°o h√†m", "t√≠ch ph√¢n", "h√¨nh h·ªçc", "ƒë·∫°i s·ªë",
            "logarit", "l∆∞·ª£ng gi√°c", "ma tr·∫≠n", "vector", "t·ªï h·ª£p",
            # V·∫≠t l√Ω, h√≥a h·ªçc
            "l·ª±c", "gia t·ªëc", "nƒÉng l∆∞·ª£ng", "nguy√™n t·ª≠", "ph·∫£n ·ª©ng h√≥a h·ªçc",
            # L·ªãch s·ª≠, ƒë·ªãa l√Ω
            "chi·∫øn tranh", "vua", "tri·ªÅu ƒë·∫°i", "l√£nh th·ªï", "ƒë·∫•t n∆∞·ªõc",
            # Th·ªùi ti·∫øt, ·∫©m th·ª±c
            "th·ªùi ti·∫øt", "n·∫•u ƒÉn", "m√≥n ƒÉn", "c√¥ng th·ª©c n·∫•u",
            # Th·ªÉ thao, gi·∫£i tr√≠
            "b√≥ng ƒë√°", "ca sƒ©", "phim", "√¢m nh·∫°c",
            # L·∫≠p tr√¨nh (n·∫øu kh√¥ng li√™n quan ƒë√†o t·∫°o)
            "code python", "l·∫≠p tr√¨nh java", "debug", "algorithm",
            # Y t·∫ø
            "b·ªánh", "thu·ªëc", "tri·ªáu ch·ª©ng", "ƒëi·ªÅu tr·ªã"
        ]
        if any(pattern in query_lower for pattern in out_of_domain_patterns):
            return "out_of_domain"
        
        # Ki·ªÉm tra c√°c t·ª´ kh√≥a TRONG domain (quy ch·∫ø ƒë√†o t·∫°o HaUI)
        domain_keywords = [
            "sinh vi√™n", "h·ªçc ph·∫ßn", "t√≠n ch·ªâ", "ƒëi·ªÉm", "thi", "t·ªët nghi·ªáp",
            "ƒë√†o t·∫°o", "h·ªçc k·ª≥", "ch∆∞∆°ng tr√¨nh", "quy ch·∫ø", "ƒëi·ªÅu", "ch∆∞∆°ng",
            "ƒëƒÉng k√Ω", "r√∫t b·ªõt", "ngh·ªâ h·ªçc", "b·∫£o l∆∞u", "k·ª∑ lu·∫≠t",
            "gpa", "cpa", "haui", "ƒë·∫°i h·ªçc c√¥ng nghi·ªáp"
        ]
        
        # N·∫øu c√≥ t·ª´ kh√≥a domain -> ch·∫Øc ch·∫Øn l√† document_related
        if any(keyword in query_lower for keyword in domain_keywords):
            return "document_related"
        
        # N·∫øu kh√¥ng match g√¨ c·∫£, d√πng LLM ƒë·ªÉ ki·ªÉm tra (fallback)
        # T·∫°m th·ªùi return document_related, nh∆∞ng c√≥ th·ªÉ c·∫£i thi·ªán sau
        return "document_related"
    
    def _handle_greeting(self, query: str) -> str:
        """X·ª≠ l√Ω c√¢u ch√†o h·ªèi"""
        greetings = [
            "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp H√† N·ªôi. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu v·ªÅ quy ch·∫ø ƒë√†o t·∫°o. B·∫°n c√≥ c√¢u h·ªèi g√¨ kh√¥ng?",
            "Ch√†o b·∫°n! T√¥i s·∫µn s√†ng h·ªó tr·ª£ b·∫°n v·ªÅ c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn quy ƒë·ªãnh ƒë√†o t·∫°o t·∫°i HaUI. H√£y ƒë·∫∑t c√¢u h·ªèi nh√©!",
            "Xin ch√†o! R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ quy ch·∫ø ƒë√†o t·∫°o, ƒëi·ªÅu ki·ªán t·ªët nghi·ªáp, v√† c√°c quy ƒë·ªãnh kh√°c c·ªßa tr∆∞·ªùng. B·∫°n c·∫ßn h·ªèi g√¨?"
        ]
        import random
        return random.choice(greetings)
    
    def _handle_meta_question(self, query: str, history: List[Dict[str, str]]) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ ch√≠nh cu·ªôc h·ªôi tho·∫°i"""
        if not history or len(history) < 2:
            return "B·∫°n ch∆∞a h·ªèi c√¢u n√†o tr∆∞·ªõc ƒë√≥ trong cu·ªôc h·ªôi tho·∫°i n√†y."
        
        # L·∫•y T·∫§T C·∫¢ c√¢u h·ªèi c·ªßa user
        user_messages = [msg for msg in history if msg.get("role") == "user"]
        
        if not user_messages:
            return "T√¥i kh√¥ng t√¨m th·∫•y c√¢u h·ªèi n√†o c·ªßa b·∫°n trong cu·ªôc h·ªôi tho·∫°i n√†y."
        
        query_lower = query.lower()
        
        # Ph√¢n bi·ªát: h·ªèi T·∫§T C·∫¢ vs ch·ªâ c√¢u TR∆Ø·ªöC
        all_questions_patterns = [
            "t·∫•t c·∫£", "all", "to√†n b·ªô", "nh·ªØng c√¢u", "c√°c c√¢u",
            "danh s√°ch", "list", "l·ªãch s·ª≠"
        ]
        
        ask_for_all = any(pattern in query_lower for pattern in all_questions_patterns)
        
        if ask_for_all and len(user_messages) > 1:
            # Tr·∫£ v·ªÅ T·∫§T C·∫¢ c√¢u h·ªèi
            response = f"üìù B·∫°n ƒë√£ h·ªèi t·ªïng c·ªông {len(user_messages)} c√¢u h·ªèi trong cu·ªôc h·ªôi tho·∫°i n√†y:\n\n"
            
            for idx, msg in enumerate(user_messages, 1):
                question = msg.get("content", "")
                # Gi·ªõi h·∫°n ƒë·ªô d√†i hi·ªÉn th·ªã
                if len(question) > 80:
                    question = question[:77] + "..."
                response += f"{idx}. {question}\n"
            
            response += "\nB·∫°n mu·ªën h·ªèi th√™m v·ªÅ v·∫•n ƒë·ªÅ n√†o kh√¥ng?"
            return response
        else:
            # Ch·ªâ tr·∫£ v·ªÅ c√¢u CU·ªêI C√ôNG
            last_question = user_messages[-1].get("content", "")
            return f'C√¢u h·ªèi tr∆∞·ªõc ƒë√≥ c·ªßa b·∫°n l√†: "{last_question}"\n\nB·∫°n c√≥ mu·ªën h·ªèi th√™m v·ªÅ v·∫•n ƒë·ªÅ n√†y kh√¥ng?'

    
    def _handle_chitchat(self, query: str) -> str:
        """X·ª≠ l√Ω chitchat"""
        query_lower = query.lower()
        
        if "b·∫°n l√† ai" in query_lower or "t√™n b·∫°n" in query_lower:
            return "T√¥i l√† tr·ª£ l√Ω AI c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp H√† N·ªôi, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ h·ªó tr·ª£ sinh vi√™n v√† gi·∫£ng vi√™n v·ªÅ c√°c quy ƒë·ªãnh ƒë√†o t·∫°o. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu v·ªÅ quy ch·∫ø ƒë√†o t·∫°o, ƒëi·ªÅu ki·ªán t·ªët nghi·ªáp, v√† c√°c quy ƒë·ªãnh kh√°c c·ªßa tr∆∞·ªùng."
        elif "c·∫£m ∆°n" in query_lower or "thank" in query_lower:
            return "R·∫•t vui ƒë∆∞·ª£c gi√∫p ƒë·ª° b·∫°n! N·∫øu c√≥ c√¢u h·ªèi g√¨ kh√°c v·ªÅ quy ch·∫ø ƒë√†o t·∫°o, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi nh√©. üòä"
        elif "t·∫°m bi·ªát" in query_lower or "bye" in query_lower:
            return "T·∫°m bi·ªát! Ch√∫c b·∫°n h·ªçc t·∫≠p t·ªët. H·∫πn g·∫∑p l·∫°i! üëã"
        else:
            return "T√¥i ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ quy ch·∫ø ƒë√†o t·∫°o t·∫°i ƒêH C√¥ng nghi·ªáp H√† N·ªôi. B·∫°n c√≥ c√¢u h·ªèi g√¨ v·ªÅ quy ƒë·ªãnh ƒë√†o t·∫°o, ƒëi·ªÅu ki·ªán t·ªët nghi·ªáp, ho·∫∑c c√°c v·∫•n ƒë·ªÅ h·ªçc t·∫≠p kh√¥ng?"
    
    def _handle_out_of_domain(self, query: str) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi ngo√†i domain"""
        return """Xin l·ªói, c√¢u h·ªèi c·ªßa b·∫°n kh√¥ng thu·ªôc ph·∫°m vi chuy√™n m√¥n c·ªßa t√¥i. 

T√¥i l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ **Quy ch·∫ø ƒê√†o t·∫°o c·ªßa ƒê·∫°i h·ªçc C√¥ng nghi·ªáp H√† N·ªôi**. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi c√°c v·∫•n ƒë·ªÅ nh∆∞:
‚Ä¢ Quy ƒë·ªãnh v·ªÅ h·ªçc t·∫≠p, thi c·ª≠, v√† t·ªët nghi·ªáp
‚Ä¢ ƒêi·ªÅu ki·ªán, th·ªß t·ª•c li√™n quan ƒë·∫øn ƒë√†o t·∫°o
‚Ä¢ C√°c quy ch·∫ø, quy ƒë·ªãnh c·ªßa tr∆∞·ªùng
‚Ä¢ C√¢u h·ªèi v·ªÅ h·ªçc ph·∫ßn, t√≠n ch·ªâ, GPA/CPA

B·∫°n c√≥ c√¢u h·ªèi n√†o li√™n quan ƒë·∫øn ƒë√†o t·∫°o t·∫°i HaUI m√† t√¥i c√≥ th·ªÉ gi√∫p kh√¥ng?"""


class RetrievalPlannerAgent:
    """
    Agent l·∫≠p k·∫ø ho·∫°ch retrieval
    Nhi·ªám v·ª•: Quy·∫øt ƒë·ªãnh chi·∫øn l∆∞·ª£c retrieval d·ª±a tr√™n query analysis
    """
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.reformulation_tool = QueryReformulationTool(llm)
    
    def plan(self, state: AgentState) -> AgentState:
        """L·∫≠p k·∫ø ho·∫°ch retrieval"""
        query = state["original_query"]
        analysis = state.get("query_analysis", {})
        complexity = analysis.get("complexity", "medium")
        
        if system_config.verbose:
            print(f"\nüìã [RetrievalPlanner] Planning retrieval strategy...")
        
        # X√°c ƒë·ªãnh strategy d·ª±a tr√™n complexity
        if complexity == "simple":
            strategy = "single_query"
            queries = [query]
        elif complexity == "medium":
            strategy = "multi_query"
            if agent_config.enable_multi_query:
                queries = self.reformulation_tool.reformulate(query)
            else:
                queries = [query]
        else:  # complex
            strategy = "multi_query_with_expansion"
            if agent_config.enable_multi_query:
                queries = self.reformulation_tool.reformulate(query)
                if agent_config.enable_query_expansion:
                    expanded = self.reformulation_tool.expand_query(query)
                    queries.append(expanded)
            else:
                queries = [query]
        
        if system_config.verbose:
            print(f"   Strategy: {strategy}")
            print(f"   Generated {len(queries)} queries")
        
        # C·∫≠p nh·∫≠t state
        state["retrieval_strategy"] = strategy
        state["reformulated_queries"] = queries
        state["current_step"] = "retrieval_planned"
        
        return state


class RetrievalAgent:
    """
    Agent th·ª±c hi·ªán retrieval
    Nhi·ªám v·ª•: T√¨m ki·∫øm documents t·ª´ vector store
    """
    
    def __init__(self, vectorstore: Chroma):
        self.search_tool = VectorSearchTool(vectorstore)
    
    def retrieve(self, state: AgentState) -> AgentState:
        """Th·ª±c hi·ªán retrieval"""
        queries = state.get("reformulated_queries", [state["original_query"]])
        
        if system_config.verbose:
            print(f"\nüîé [Retrieval] Searching with {len(queries)} queries...")
        
        all_documents = []
        seen_contents = set()  # ƒê·ªÉ tr√°nh duplicate
        
        for query in queries:
            results = self.search_tool.search(query)
            
            for doc in results:
                # Ch·ªâ th√™m n·∫øu ch∆∞a c√≥ (d·ª±a v√†o content)
                content_hash = hash(doc["content"])
                if content_hash not in seen_contents:
                    seen_contents.add(content_hash)
                    all_documents.append(doc)
        
        # S·∫Øp x·∫øp theo similarity score
        all_documents.sort(key=lambda x: x.get("similarity_score", 0), reverse=True)
        
        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
        top_documents = all_documents[:agent_config.top_k if hasattr(agent_config, 'top_k') else 10]
        
        if system_config.verbose:
            print(f"   Retrieved {len(top_documents)} unique documents")
            if top_documents:
                print(f"   Top similarity: {top_documents[0].get('similarity_score', 0):.3f}")
        
        # C·∫≠p nh·∫≠t state
        state["retrieved_documents"] = top_documents
        state["current_step"] = "documents_retrieved"
        
        return state


class ReasoningAgent:
    """
    Agent th·ª±c hi·ªán reasoning
    Nhi·ªám v·ª•: Suy lu·∫≠n t·ª´ documents ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
    """
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.extraction_tool = InformationExtractionTool(llm)
    
    def reason(self, state: AgentState) -> AgentState:
        """Th·ª±c hi·ªán reasoning"""
        query = state["original_query"]
        documents = state.get("retrieved_documents", [])
        analysis = state.get("query_analysis", {})
        
        if system_config.verbose:
            print(f"\nüß† [Reasoning] Processing {len(documents)} documents...")
        
        if not documents:
            state["final_answer"] = "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü d·ªØ li·ªáu."
            state["confidence_score"] = 0.0
            state["current_step"] = "reasoning_completed"
            return state
        
        # Chain of Thought reasoning n·∫øu c√¢u h·ªèi ph·ª©c t·∫°p
        if agent_config.enable_chain_of_thought and analysis.get("complexity") == "complex":
            answer = self._chain_of_thought_reasoning(query, documents, analysis)
        else:
            answer = self._direct_reasoning(query, documents)
        
        # Tr√≠ch xu·∫•t citations
        citations = self._extract_citations(documents)
        
        # T√≠nh confidence score d·ª±a tr√™n similarity scores
        if documents:
            avg_similarity = sum(doc.get("similarity_score", 0) for doc in documents[:3]) / min(3, len(documents))
            confidence = min(0.95, avg_similarity)
        else:
            confidence = 0.0
        
        if system_config.verbose:
            print(f"   Confidence: {confidence:.2f}")
        
        # C·∫≠p nh·∫≠t state
        state["final_answer"] = answer
        state["confidence_score"] = confidence
        state["citations"] = citations
        state["current_step"] = "reasoning_completed"
        
        return state
    
    def _direct_reasoning(self, query: str, documents: List[Dict[str, Any]]) -> str:
        """Reasoning tr·ª±c ti·∫øp t·ª´ documents"""
        # T·∫°o context
        context = "\n\n---\n\n".join([
            f"[Ngu·ªìn: {doc.get('doc_type', 'Unknown')}]\n{doc['content']}" 
            for doc in documents[:5]
        ])
        
        prompt = f"""{system_config.system_role}

D·ª±a v√†o c√°c t√†i li·ªáu sau, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß.

T√ÄI LI·ªÜU THAM KH·∫¢O:
{context}

C√ÇU H·ªéI: {query}

Y√äU C·∫¶U:
1. Tr·∫£ l·ªùi ch√≠nh x√°c d·ª±a tr√™n t√†i li·ªáu
2. Tr√≠ch d·∫´n c·ª• th·ªÉ (ƒêi·ªÅu s·ªë, Ch∆∞∆°ng s·ªë)
3. N·∫øu c√≥ nhi·ªÅu ƒëi·ªÅu ki·ªán, li·ªát k√™ r√µ r√†ng
4. N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, n√≥i r√µ

TR·∫¢ L·ªúI:"""
        
        response = self.llm.invoke(prompt)
        return response.content.strip()
    
    def _chain_of_thought_reasoning(self, query: str, documents: List[Dict[str, Any]], analysis: Dict) -> str:
        """Chain of Thought reasoning cho c√¢u h·ªèi ph·ª©c t·∫°p"""
        sub_questions = analysis.get("sub_questions", [])
        
        if not sub_questions:
            return self._direct_reasoning(query, documents)
        
        # Tr·∫£ l·ªùi t·ª´ng c√¢u h·ªèi con
        intermediate_answers = []
        
        for i, sub_q in enumerate(sub_questions, 1):
            if system_config.verbose:
                print(f"   Sub-question {i}: {sub_q}")
            
            answer = self._direct_reasoning(sub_q, documents)
            intermediate_answers.append(f"**C√¢u h·ªèi {i}:** {sub_q}\n**Tr·∫£ l·ªùi:** {answer}")
        
        # T·ªïng h·ª£p c√¢u tr·∫£ l·ªùi
        context = "\n\n".join(intermediate_answers)
        
        synthesis_prompt = f"""D·ª±a v√†o c√°c c√¢u tr·∫£ l·ªùi cho c√°c c√¢u h·ªèi con, h√£y t·ªïng h·ª£p th√†nh m·ªôt c√¢u tr·∫£ l·ªùi ho√†n ch·ªânh cho c√¢u h·ªèi g·ªëc.

C√ÇU H·ªéI G·ªêC: {query}

C√ÅC C√ÇU TR·∫¢ L·ªúI CON:
{context}

H√£y t·ªïng h·ª£p th√†nh c√¢u tr·∫£ l·ªùi m·∫°ch l·∫°c, ƒë·∫ßy ƒë·ªß v√† d·ªÖ hi·ªÉu."""
        
        response = self.llm.invoke(synthesis_prompt)
        return response.content.strip()
    
    def _extract_citations(self, documents: List[Dict[str, Any]]) -> List[str]:
        """Tr√≠ch xu·∫•t citations t·ª´ documents"""
        citations = []
        for doc in documents[:3]:  # Top 3 documents
            source = doc.get("doc_type", "Unknown")
            citations.append(source)
        return list(set(citations))  # Remove duplicates


class ValidationAgent:
    """
    Agent validate c√¢u tr·∫£ l·ªùi
    Nhi·ªám v·ª•: Ki·ªÉm tra ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi
    """
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.validation_tool = ValidationTool(llm)
    
    def validate(self, state: AgentState) -> AgentState:
        """Validate c√¢u tr·∫£ l·ªùi"""
        if not agent_config.enable_answer_validation:
            state["validation_result"] = {"is_valid": True, "confidence": 1.0}
            state["needs_retry"] = False
            state["current_step"] = "validation_completed"
            return state
        
        query = state["original_query"]
        answer = state.get("final_answer", "")
        documents = state.get("retrieved_documents", [])
        confidence = state.get("confidence_score", 0.0)
        
        if system_config.verbose:
            print(f"\n‚úì [Validation] Validating answer...")
        
        # Validate
        validation_result = self.validation_tool.validate(query, answer, documents)
        
        is_valid = validation_result.get("is_valid", False)
        val_confidence = validation_result.get("confidence", 0.0)
        
        # Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn retry kh√¥ng
        needs_retry = (
            not is_valid or 
            val_confidence < agent_config.min_confidence_score or
            confidence < agent_config.min_confidence_score
        ) and state.get("retry_count", 0) < agent_config.max_retries
        
        if system_config.verbose:
            print(f"   Valid: {is_valid}, Confidence: {val_confidence:.2f}")
            if needs_retry:
                print(f"   ‚ö†Ô∏è Needs retry (attempt {state.get('retry_count', 0) + 1}/{agent_config.max_retries})")
        
        # C·∫≠p nh·∫≠t state
        state["validation_result"] = validation_result
        state["needs_retry"] = needs_retry
        state["current_step"] = "validation_completed"
        
        return state


class ResponseFormatterAgent:
    """
    Agent format c√¢u tr·∫£ l·ªùi cu·ªëi c√πng
    Nhi·ªám v·ª•: Format c√¢u tr·∫£ l·ªùi v·ªõi citations, confidence, etc.
    """
    
    def format(self, state: AgentState) -> AgentState:
        """Format c√¢u tr·∫£ l·ªùi"""
        answer = state.get("final_answer", "")
        citations = state.get("citations", [])
        confidence = state.get("confidence_score", 0.0)
        
        if system_config.verbose:
            print(f"\nüìù [Formatter] Formatting final response...")
        
        # Format v·ªõi citations n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if agent_config.require_citations and citations:
            formatted_answer = f"{answer}\n\n---\n**Ngu·ªìn tham kh·∫£o:** {', '.join(citations)}"
        else:
            formatted_answer = answer
        
        # Th√™m confidence warning n·∫øu th·∫•p
        if confidence < 0.7:
            formatted_answer += f"\n\n*L∆∞u √Ω: ƒê·ªô tin c·∫≠y c·ªßa c√¢u tr·∫£ l·ªùi n√†y l√† {confidence:.0%}. Vui l√≤ng ki·ªÉm tra l·∫°i ho·∫∑c h·ªèi c·ª• th·ªÉ h∆°n.*"
        
        state["final_answer"] = formatted_answer
        state["current_step"] = "response_formatted"
        
        return state


if __name__ == "__main__":
    print("‚úÖ Agents module loaded successfully")
    print(f"üì¶ Available agents:")
    print(f"   - QueryAnalyzerAgent")
    print(f"   - RetrievalPlannerAgent")
    print(f"   - RetrievalAgent")
    print(f"   - ReasoningAgent")
    print(f"   - ValidationAgent")
    print(f"   - ResponseFormatterAgent")
