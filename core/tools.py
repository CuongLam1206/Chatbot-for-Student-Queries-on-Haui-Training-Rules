"""
Tools cho Agentic RAG System
ƒê·ªãnh nghƒ©a c√°c c√¥ng c·ª• m√† agents c√≥ th·ªÉ s·ª≠ d·ª•ng
"""

from typing import List, Dict, Any, Optional
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from rank_bm25 import BM25Okapi
import re
from .config import model_config, vectorstore_config, agent_config


class VectorSearchTool:
    """Tool ƒë·ªÉ search trong vector database"""
    
    def __init__(self, vectorstore: Chroma):
        self.vectorstore = vectorstore
        self.top_k = vectorstore_config.top_k
    
    def search(self, query: str, k: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        T√¨m ki·∫øm trong vector database
        
        Args:
            query: C√¢u query
            k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ (m·∫∑c ƒë·ªãnh d√πng config)
        
        Returns:
            List c√°c documents v·ªõi metadata v√† similarity scores
        """
        k = k or self.top_k
        
        # Similarity search v·ªõi scores
        results = self.vectorstore.similarity_search_with_score(query, k=k)
        
        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity_score": float(score),
                "source": doc.metadata.get("source", "Unknown"),
                "doc_type": doc.metadata.get("doc_type", "Unknown")
            })
        
        return formatted_results
    
    def search_with_filter(self, query: str, filter_dict: Dict[str, Any], k: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        Search v·ªõi metadata filtering
        
        Args:
            query: C√¢u query
            filter_dict: ƒêi·ªÅu ki·ªán l·ªçc, v√≠ d·ª•: {"doc_type": "Chapter I"}
            k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£
        """
        k = k or self.top_k
        
        results = self.vectorstore.similarity_search_with_score(
            query, 
            k=k,
            filter=filter_dict
        )
        
        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity_score": float(score)
            })
        
        return formatted_results


class QueryReformulationTool:
    """Tool ƒë·ªÉ c·∫£i thi·ªán v√† reformulate queries"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    def reformulate(self, original_query: str, context: str = "") -> List[str]:
        """
        T·∫°o c√°c phi√™n b·∫£n query kh√°c nhau ƒë·ªÉ tƒÉng kh·∫£ nƒÉng t√¨m ƒë∆∞·ª£c th√¥ng tin
        
        Args:
            original_query: Query g·ªëc
            context: Context b·ªï sung (n·∫øu c√≥)
        
        Returns:
            List c√°c query ƒë√£ ƒë∆∞·ª£c reformulate
        """
        prompt = f"""B·∫°n l√† chuy√™n gia v·ªÅ quy ch·∫ø ƒë√†o t·∫°o. H√£y t·∫°o {agent_config.max_query_reformulations} c√°ch di·ªÖn ƒë·∫°t kh√°c nhau cho c√¢u h·ªèi sau ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin hi·ªáu qu·∫£ h∆°n.

C√¢u h·ªèi g·ªëc: {original_query}

Y√™u c·∫ßu:
1. Gi·ªØ nguy√™n √Ω nghƒ©a c√¢u h·ªèi
2. S·ª≠ d·ª•ng t·ª´ kh√≥a v√† thu·∫≠t ng·ªØ ch√≠nh th·ª©c trong quy ch·∫ø
3. M·ªói c√°ch di·ªÖn ƒë·∫°t n√™n t·∫≠p trung v√†o kh√≠a c·∫°nh kh√°c nhau c·ªßa c√¢u h·ªèi

Tr·∫£ v·ªÅ {agent_config.max_query_reformulations} c√¢u h·ªèi, m·ªói c√¢u tr√™n m·ªôt d√≤ng, kh√¥ng ƒë√°nh s·ªë."""

        response = self.llm.invoke(prompt)
        queries = [q.strip() for q in response.content.strip().split('\n') if q.strip()]
        
        # Lu√¥n bao g·ªìm query g·ªëc
        if original_query not in queries:
            queries.insert(0, original_query)
        
        return queries[:agent_config.max_query_reformulations + 1]
    
    def expand_query(self, query: str) -> str:
        """
        M·ªü r·ªông query v·ªõi c√°c t·ª´ ƒë·ªìng nghƒ©a v√† thu·∫≠t ng·ªØ li√™n quan
        """
        prompt = f"""H√£y m·ªü r·ªông c√¢u h·ªèi sau b·∫±ng c√°ch th√™m c√°c t·ª´ ƒë·ªìng nghƒ©a, thu·∫≠t ng·ªØ li√™n quan trong quy ch·∫ø ƒë√†o t·∫°o:

C√¢u h·ªèi: {query}

Tr·∫£ v·ªÅ c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c m·ªü r·ªông (ch·ªâ 1 c√¢u duy nh·∫•t)."""

        response = self.llm.invoke(prompt)
        return response.content.strip()


class QueryAnalysisTool:
    """Tool ƒë·ªÉ ph√¢n t√≠ch query c·ªßa user"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    def analyze(self, query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch c√¢u h·ªèi ƒë·ªÉ hi·ªÉu intent v√† tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng
        
        Returns:
            Dict ch·ª©a:
            - intent: M·ª•c ƒë√≠ch c√¢u h·ªèi (query, definition, procedure, comparison, etc.)
            - key_terms: C√°c t·ª´ kh√≥a quan tr·ªçng
            - entities: C√°c th·ª±c th·ªÉ (ƒêi·ªÅu X, Ch∆∞∆°ng Y, etc.)
            - complexity: ƒê·ªô ph·ª©c t·∫°p (simple, medium, complex)
            - sub_questions: C√°c c√¢u h·ªèi con (n·∫øu c√≥)
        """
        prompt = f"""Ph√¢n t√≠ch c√¢u h·ªèi sau v·ªÅ quy ch·∫ø ƒë√†o t·∫°o:

C√¢u h·ªèi: {query}

H√£y tr·∫£ v·ªÅ ph√¢n t√≠ch theo format JSON v·ªõi c√°c tr∆∞·ªùng:
- intent: Lo·∫°i c√¢u h·ªèi (query: h·ªèi th√¥ng tin, definition: h·ªèi ƒë·ªãnh nghƒ©a, procedure: h·ªèi quy tr√¨nh, comparison: so s√°nh, calculation: t√≠nh to√°n)
- key_terms: List c√°c t·ª´ kh√≥a quan tr·ªçng
- entities: List c√°c th·ª±c th·ªÉ c·ª• th·ªÉ (ƒêi·ªÅu s·ªë, Ch∆∞∆°ng s·ªë, h·ªçc ph·∫ßn, ƒëi·ªÉm s·ªë, etc.)
- complexity: simple/medium/complex
- sub_questions: N·∫øu c√¢u h·ªèi ph·ª©c t·∫°p, chia th√†nh c√°c c√¢u h·ªèi con (list)

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch th√™m."""

        response = self.llm.invoke(prompt)
        
        # Parse JSON response
        import json
        try:
            result = json.loads(response.content.strip())
        except:
            # Fallback n·∫øu kh√¥ng parse ƒë∆∞·ª£c
            result = {
                "intent": "query",
                "key_terms": self._extract_keywords(query),
                "entities": self._extract_entities(query),
                "complexity": "medium",
                "sub_questions": []
            }
        
        return result
    
    def _extract_keywords(self, query: str) -> List[str]:
        """Extract keywords ƒë∆°n gi·∫£n b·∫±ng regex"""
        # Lo·∫°i b·ªè stop words ti·∫øng Vi·ªát c∆° b·∫£n
        stop_words = {'l√†', 'c·ªßa', 'v√†', 'c√≥', 'ƒë∆∞·ª£c', 'trong', 'cho', 'v·ªõi', 'ƒë·ªÉ', 'khi', 'n√†o', 'nh∆∞', 'v·ªÅ'}
        words = re.findall(r'\w+', query.lower())
        return [w for w in words if w not in stop_words and len(w) > 2]
    
    def _extract_entities(self, query: str) -> List[str]:
        """Extract entities nh∆∞ ƒêi·ªÅu X, Ch∆∞∆°ng Y"""
        entities = []
        
        # Extract ƒêi·ªÅu X
        dieu_matches = re.findall(r'ƒêi·ªÅu\s+\d+', query)
        entities.extend(dieu_matches)
        
        # Extract Ch∆∞∆°ng X
        chuong_matches = re.findall(r'Ch∆∞∆°ng\s+[IVX]+', query, re.IGNORECASE)
        entities.extend(chuong_matches)
        
        return entities


class InformationExtractionTool:
    """Tool ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin c·ª• th·ªÉ t·ª´ documents"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    def extract(self, documents: List[Dict[str, Any]], query: str) -> str:
        """
        Tr√≠ch xu·∫•t th√¥ng tin li√™n quan ƒë·∫øn query t·ª´ documents
        
        Args:
            documents: List c√°c documents t·ª´ retrieval
            query: C√¢u h·ªèi g·ªëc
        
        Returns:
            Th√¥ng tin ƒë√£ ƒë∆∞·ª£c tr√≠ch xu·∫•t v√† t·ªïng h·ª£p
        """
        # T·∫°o context t·ª´ documents
        context = "\n\n---\n\n".join([
            f"[{doc['doc_type']}]\n{doc['content']}" 
            for doc in documents
        ])
        
        prompt = f"""D·ª±a v√†o c√°c ƒëo·∫°n vƒÉn b·∫£n sau t·ª´ quy ch·∫ø ƒë√†o t·∫°o, h√£y tr√≠ch xu·∫•t th√¥ng tin tr·∫£ l·ªùi c√¢u h·ªèi.

C√ÇU H·ªéI: {query}

T√ÄI LI·ªÜU:
{context}

H√£y tr√≠ch xu·∫•t v√† t·ªïng h·ª£p th√¥ng tin c√≥ li√™n quan. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ t√†i li·ªáu, kh√¥ng b·ªãa th√™m."""

        response = self.llm.invoke(prompt)
        return response.content.strip()


class ValidationTool:
    """Tool ƒë·ªÉ validate c√¢u tr·∫£ l·ªùi"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    def validate(self, query: str, answer: str, source_documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Validate xem c√¢u tr·∫£ l·ªùi c√≥ ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c kh√¥ng
        
        Returns:
            Dict ch·ª©a:
            - is_valid: bool
            - confidence: float (0-1)
            - issues: List c√°c v·∫•n ƒë·ªÅ (n·∫øu c√≥)
            - suggestions: G·ª£i √Ω c·∫£i thi·ªán
        """
        context = "\n".join([doc['content'] for doc in source_documents])
        
        prompt = f"""ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi sau:

C√ÇU H·ªéI: {query}

C√ÇU TR·∫¢ L·ªúI: {answer}

T√ÄI LI·ªÜU THAM KH·∫¢O:
{context}

H√£y ƒë√°nh gi√° theo c√°c ti√™u ch√≠:
1. C√¢u tr·∫£ l·ªùi c√≥ tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß c√¢u h·ªèi kh√¥ng?
2. Th√¥ng tin c√≥ ch√≠nh x√°c d·ª±a tr√™n t√†i li·ªáu kh√¥ng?
3. C√≥ thi·∫øu th√¥ng tin quan tr·ªçng n√†o kh√¥ng?
4. C√≥ th√¥ng tin sai l·ªách ho·∫∑c b·ªãa ƒë·∫∑t kh√¥ng?

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
  "is_valid": true/false,
  "confidence": 0.0-1.0,
  "issues": ["v·∫•n ƒë·ªÅ 1", "v·∫•n ƒë·ªÅ 2"],
  "suggestions": ["g·ª£i √Ω 1", "g·ª£i √Ω 2"]
}}

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch."""

        response = self.llm.invoke(prompt)
        
        import json
        try:
            result = json.loads(response.content.strip())
        except:
            # Fallback
            result = {
                "is_valid": True,
                "confidence": 0.7,
                "issues": [],
                "suggestions": []
            }
        
        return result


if __name__ == "__main__":
    # Test tools
    print("‚úÖ Tools module loaded successfully")
    print(f"üì¶ Available tool classes: VectorSearchTool, QueryReformulationTool, QueryAnalysisTool, InformationExtractionTool, ValidationTool")
